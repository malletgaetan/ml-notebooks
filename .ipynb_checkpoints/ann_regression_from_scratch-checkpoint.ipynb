{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.concat(pd.read_excel(\"Folds5x2_pp.xlsx\", sheet_name=None), ignore_index=True)\n",
    "\n",
    "train_dataset = df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "def normalize(df):\n",
    "    for key in df.keys():\n",
    "        df[key] = df[key] / df[key].max()\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "train_features = normalize(train_dataset.drop([\"PE\"], axis=1))\n",
    "test_features = normalize(test_dataset.drop([\"PE\"], axis=1))\n",
    "train_labels = train_dataset[\"PE\"].values.reshape(1, -1)[0]\n",
    "test_labels = test_dataset[\"PE\"].values.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_size = len(train_features[0])\n",
    "\n",
    "# DAMN NETWORK\n",
    "w1 = np.random.randint(1, 2, (input_size, 3))\n",
    "b1 = np.random.randint(1, 2, (3,))\n",
    "w2 = np.random.randint(1, 2, (3, 1))\n",
    "b2 = np.random.randint(1, 2, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def sqrt_mean_squared_error(x, y):\n",
    "    return np.square(x - y).sum() / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA\n",
    "# function to create a list containing mini-batches\n",
    "def create_mini_batches(X, y, batch_size):\n",
    "    mini_batches = []\n",
    "    data = np.hstack((X, y))\n",
    "    np.random.shuffle(data)\n",
    "    n_minibatches = data.shape[0] // batch_size\n",
    "    i = 0\n",
    "  \n",
    "    for i in range(n_minibatches + 1):\n",
    "        mini_batch = data[i * batch_size:(i + 1)*batch_size, :]\n",
    "        X_mini = mini_batch[:, :-1]\n",
    "        Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "        mini_batches.append((X_mini, Y_mini))\n",
    "    if data.shape[0] % batch_size != 0:\n",
    "        mini_batch = data[i * batch_size:data.shape[0]]\n",
    "        X_mini = mini_batch[:, :-1]\n",
    "        Y_mini = mini_batch[:, -1].reshape((-1, 1))\n",
    "        mini_batches.append((X_mini, Y_mini))\n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "def forward(x, w1, w2, b1, b2):\n",
    "    # FORWARD PROPAGATION\n",
    "    # Z1(3,m) = ((W1(4,3).T(3,4) * X(4,m))(3,m) + b(3,m))\n",
    "    z1 = w1.T.dot(x.T).T + b1\n",
    "    # A1(3,m) = A(Z1(3,m))\n",
    "    a1 = sigmoid(z1)\n",
    "    # Z2(1,1) = ((W2(3,m).T(m,3) * A1(3,m))(2,1) + b(1,1))\n",
    "    z2 = (w2.T.dot(a1.T) + b2)\n",
    "    # A2(1,m) = A(Z2(1,m))\n",
    "    # WE DON'T USE SIGMOID HERE TILL WE WANT A NUMBER AS RESULT\n",
    "    a2 = z2\n",
    "    return a2\n",
    "\n",
    "# create batches that contains 50 (X,y) each\n",
    "mini_batches = create_mini_batches(train_features, train_labels.reshape(len(train_labels), 1), 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS ENTIRE PROCESS COUNT AS AN EPOCH\n",
    "\n",
    "# LEARNING_RATE\n",
    "λ = 0.01\n",
    "\n",
    "def gradient_descent(mini_batches, lw1, lw2, lb1, lb2):\n",
    "    # mini_batch = zip(train_features, train_labels)\n",
    "    for x, y in mini_batches[0:-2]:\n",
    "        # GRADIENT TO BE\n",
    "        dJdB1 = [np.zeros(b.shape) for b in lb1]\n",
    "        dJdW1 = [np.zeros(w.shape) for w in lw1]\n",
    "        dJdB2 = [np.zeros(b.shape) for b in lb2]\n",
    "        dJdW2 = [np.zeros(w.shape) for w in lw2]\n",
    "\n",
    "        # CALLED m IN SHAPES COMMENTS\n",
    "        batch_size = len(x)\n",
    "\n",
    "        # FORWARD PROPAGATION\n",
    "        # Z1(3,m) = ((W1(4,3).T(3,4) * X(4,m))(3,m) + b(3,m))\n",
    "        z1 = lw1.T.dot(x.T).T + lb1\n",
    "        # A1(3,m) = A(Z1(3,m))\n",
    "        a1 = sigmoid(z1)\n",
    "        # Z2(1,1) = ((W2(3,m).T(m,3) * A1(3,m))(2,1) + b(1,1))\n",
    "        z2 = (lw2.T.dot(a1.T) + lb2)\n",
    "        # A2(1,m) = A(Z2(1,m))\n",
    "        # WE DON'T USE SIGMOID HERE TILL WE WANT A NUMBER AS RESULT\n",
    "        a2 = z2\n",
    "        \n",
    "        # BACKWARD PROPAGATION\n",
    "        # HERE WE DO MATHS, NO LUCK, HIGHLY SUGGEST https://www.youtube.com/watch?v=tIeHLnjs5U8\n",
    "        # dJdW2(3,m) = dZ2/dW2 * dA2/dZ2 * dJ/dA2 WITH J OUR COST FUNCTION (sqrt_mean_squared_error)\n",
    "        dJdA2 = (2 * (a2 - y.T))\n",
    "        dZ2dW2 = a1\n",
    "        dA2dZ2 = d_sigmoid(z2)\n",
    "        dJdW2 = (dA2dZ2 * dJdA2).dot(dZ2dW2).T\n",
    "        dZ2dB2 = 1\n",
    "        dJdB2 = ((dA2dZ2 * dJdA2 * dZ2dB2)/batch_size).sum(axis=1)\n",
    "\n",
    "        # HERE THE HARD PART IS ABOUT dJ/A1, which have impact on cost function thru Z2 -> A2 -> J\n",
    "        # (1, m)\n",
    "        dA2dZ2 = d_sigmoid(z2)\n",
    "        # (1, m) = (1,m) * (m, 1)\n",
    "        dJdZ2 = dA2dZ2 * dJdA2\n",
    "        # (3, m) = (3, m) * (3, m)\n",
    "        dJdZ1 = (lw2.dot(dJdZ2)).T * d_sigmoid(z1)\n",
    "        # (3, 4) = (3, m) * (m, 4)\n",
    "        dJdW1 = dJdZ1.T.dot(x).T / batch_size\n",
    "        # (1, 3) = (50, 3).sum(axis=y)\n",
    "        dJdB1 = (dJdZ1 / batch_size).sum(axis=0)\n",
    "        \n",
    "        dJdW2 = dJdW2 / batch_size\n",
    "        \n",
    "        print(dJdW1)\n",
    "        print(dJdB1)\n",
    "        print(dJdW2)\n",
    "        print(dJdB2)\n",
    "        \n",
    "        lw2 = lw2 + dJdW2\n",
    "        lb2 = lb2 + dJdB2\n",
    "        lw1 = lw1 + dJdW1\n",
    "        lb1 = lb1 + dJdB1\n",
    "        \n",
    "        return lw1, lw2, lb1, lb2\n",
    "\n",
    "# d = len(train_features)\n",
    "# w1 = [w - λ/d * dw for w, dw in zip(w1, dJdW1)]\n",
    "# w2 = [w - λ/d * dw for w, dw in zip(w2, dJdW2)]\n",
    "# b1 = [b - λ/d * dw for b, dw in zip(b1, dJdB1)]\n",
    "# b2 = [b - λ/d * dw for b, dw in zip(b2, dJdB2)]\n",
    "# print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15758639 -0.15758639 -0.15758639]\n",
      " [-0.21650994 -0.21650994 -0.21650994]\n",
      " [-0.35968096 -0.35968096 -0.35968096]\n",
      " [-0.27888283 -0.27888283 -0.27888283]]\n",
      "[-0.36630702 -0.36630702 -0.36630702]\n",
      "[[-16.71521881]\n",
      " [-16.71521881]\n",
      " [-16.71521881]]\n",
      "[-17.09028101]\n",
      "[[0.84241361 0.84241361 0.84241361]\n",
      " [0.78349006 0.78349006 0.78349006]\n",
      " [0.64031904 0.64031904 0.64031904]\n",
      " [0.72111717 0.72111717 0.72111717]]\n",
      "[[-15.71521881]\n",
      " [-15.71521881]\n",
      " [-15.71521881]]\n",
      "[0.63369298 0.63369298 0.63369298]\n",
      "[-16.09028101]\n"
     ]
    }
   ],
   "source": [
    "nw1, nw2, nb1, nb2 = gradient_descent(mini_batches, w1, w2, b1, b2)\n",
    "print(nw1)\n",
    "print(nw2)\n",
    "print(nb1)\n",
    "print(nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = mini_batches[1][0][0]\n",
    "test_label = mini_batches[1][1][0]\n",
    "print(test_feature)\n",
    "print(f\"neural network predicted {forward(test_feature, w1, w2, b1, b2)}, should be {test_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w1.shape)\n",
    "print(w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
