{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.concat(pd.read_excel(\"Folds5x2_pp.xlsx\", sheet_name=None), ignore_index=True)\n",
    "\n",
    "train_dataset = df.sample(frac=0.8, random_state=0)\n",
    "test_dataset = df.drop(train_dataset.index)\n",
    "\n",
    "def normalize(df):\n",
    "    for key in df.keys():\n",
    "        df[key] = df[key] / df[key].max()\n",
    "    return df.to_numpy()\n",
    "\n",
    "\n",
    "train_features = normalize(train_dataset.drop([\"PE\"], axis=1))\n",
    "test_features = normalize(test_dataset.drop([\"PE\"], axis=1))\n",
    "train_labels = train_dataset[\"PE\"].values.reshape(1, -1)[0]\n",
    "test_labels = test_dataset[\"PE\"].values.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_size = len(train_features[0])\n",
    "\n",
    "# DAMN NETWORK\n",
    "w1 = np.random.rand(input_size, 3)\n",
    "b1 = np.random.rand(3,)\n",
    "w2 = np.random.rand(3, 1)\n",
    "b2 = np.random.rand(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def d_sigmoid(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "def forward(x):\n",
    "    x = x.dot(w1)\n",
    "    x = x + b1\n",
    "    x = sigmoid(x)\n",
    "    x = x.dot(w2)\n",
    "    x = x + b2\n",
    "    return x\n",
    "\n",
    "def sqrt_mean_squared_error(x, y):\n",
    "    return np.square(x - y).sum() / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67727989])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINING DATA\n",
    "mini_batch = zip(train_features, train_labels)\n",
    "# print(w1.shape)\n",
    "# print(sigmoid(w1.T.dot(train_features[0]) + b1[0]))\n",
    "np.random.rand(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    }
   ],
   "source": [
    "# THIS ENTIRE PROCESS COUNT AS AN EPOCH\n",
    "\n",
    "# LEARNING_RATE\n",
    "λ = 0.01\n",
    "\n",
    "# GRADIENT TO BE\n",
    "dJdB1 = [np.zeros(b.shape) for b in w1]\n",
    "dJdW1 = [np.zeros(w.shape) for w in w1]\n",
    "dJdB2 = [np.zeros(b.shape) for b in w2]\n",
    "dJdW2 = [np.zeros(w.shape) for w in w2]\n",
    "\n",
    "\n",
    "for x, y in mini_batch:\n",
    "    # FORWARD PROPAGATION\n",
    "    # Z1(3,1) = ((W1(4,3).T(3,4) * X(4,1))(3,1) + b(3,1))\n",
    "    z1 = w1.T.dot(x) + b1\n",
    "    # A1(3,1) = A(Z1(3,1))\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    # USING RESHAPE CAUSE NUMPY (3,1) != (3,)\n",
    "    # Z2(1,1) = ((W2(3,1).T(1,3) * A1(3,1))(2,1) + b(1,1))\n",
    "    z2 = (w2.reshape(3,).T.dot(a1) + b2)\n",
    "    # A2(2,1) = A(Z2(2,1))\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    # BACKWARD PROPAGATION\n",
    "    # HERE WE DO MATHS, NO LUCK, HIGHLY SUGGEST https://www.youtube.com/watch?v=tIeHLnjs5U8\n",
    "    # BY FOLLOWING CHAIN RULE =>\n",
    "    # dJdW2(3,1) = dZ2/dW2 * dA2/dZ2 * dJ/dA2 with J our cost function\n",
    "    dJdW2 = a1 * d_sigmoid(z2) * (2 * (a2 - y))\n",
    "    \n",
    "    # dJdW2(4,3) = dZ1/dW1 * dA1/dZ1 * dJ/dA1 with J our cost function\n",
    "    # HERE THE HARD PART IS ABOUT dJ/A1, which have impact on cost function by having impact on Z2 -> A2 -> J\n",
    "    # THE NOT COOL PART IS ABOUT HAVING THOSE MATRICE DIMENSION RIGHT LOL\n",
    "#     print((x.reshape(4, 1).dot(d_sigmoid(z1).reshape(3,1).T)).shape)\n",
    "    print(w2.shape)\n",
    "#     part2 = print((w2.dot(d_sigmoid(z2)) * (2 * (a2 - y))))\n",
    "#     print((2 * (a2 - y)))\n",
    "#     print(w2.dot(z2))\n",
    "#     print((w2.dot(d_sigmoid(z2))))\n",
    "    dJdW1 = x.reshape(4, 1).dot(d_sigmoid(z1).reshape(3,1).T).dot((w2.dot(d_sigmoid(z2)) * (2 * (a2 - y))))\n",
    "#     print(w1)\n",
    "#     print(dJdW1)\n",
    "#     print(w1.shape, dJdW1.shape)\n",
    "#     print(w2.shape, dJdW2.shape)\n",
    "    break\n",
    "    # dJdB2 = dJdB2 + batch_dJdB2\n",
    "    # dJdW2 = dJdW2 + batch_dJdW2\n",
    "\n",
    "    # dJdB1 = dJdB1 + batch_dJdB1\n",
    "    # dJdW1 = dJdW1 + batch_dJdW1\n",
    "\n",
    "\n",
    "\n",
    "# d = len(train_features)\n",
    "# w1 = [w - λ/d * dw for w, dw in zip(w1, dJdW1)]\n",
    "# w2 = [w - λ/d * dw for w, dw in zip(w2, dJdW2)]\n",
    "# b1 = [b - λ/d * dw for b, dw in zip(b1, dJdB1)]\n",
    "# b2 = [b - λ/d * dw for b, dw in zip(b2, dJdB2)]\n",
    "# print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
